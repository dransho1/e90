import cv2
import gi
gi.require_version('Gst', '1.0')
from gi.repository import GObject, Gst
import numpy as np
from time import sleep
import sys
import navigator


img = None

def on_new_buffer(appsink):

    sample = appsink.emit('pull-sample')
    #get the buffer
    buf=sample.get_buffer()

    caps = sample.get_caps()

    w = caps.get_structure(0).get_value('width')
    h = caps.get_structure(0).get_value('height')

    #extract data stream as string
    data=buf.extract_dup(0,buf.get_size())

    global img
    img = np.fromstring(data, dtype='uint8').reshape((h,w,4))
    img = img[:,:,:3]

    return False



Gst.init(None)

#CLI="videotestsrc ! video/x-raw, width=640, height=480, format=BGRx ! appsink name=sink"
#CLI="autovideosrc ! videoconvert ! video/x-raw, width=640, height=480, format=BGRx ! appsink name=sink"
CLI="tcpclientsrc port=8080 host=192.168.1.104 ! gdpdepay ! rtph264depay ! avdec_h264 ! videoconvert ! video/x-raw, format=BGRx ! appsink name=sink"

#simplest way to create a pipline
pipline=Gst.parse_launch(CLI)

#getting the sink by its name set in CLI
appsink=pipline.get_by_name("sink")

#setting some important properties of appsnik
appsink.set_property("max-buffers",20) # prevent the app to consume huge part of memory
appsink.set_property('emit-signals',True) #tell sink to emit signals
appsink.set_property('sync',False) #no sync to make decoding as fast as possible
appsink.connect('new-sample', on_new_buffer) #connect signal to callable func


print 'entering playing state'
pipline.set_state(Gst.State.PLAYING)
print 'playing now'

GObject.threads_init()

cv2.namedWindow('win')
center = None
while 1:
    if img is not None:
        if not center:
            center, rad = navigator.find_circs(img)
        else:
            gci = navigator.operate_on(img, center, rad, 10)
            cv2.imshow('win', gci)
    k = cv2.waitKey(1)
    if k == 27:
        break


    


