Pre-spring break TODO:

Now try to get basic line following working, and work on really doing
more mobile robotics stuff, as well as CV stuff.
	Camera working! CV installed.

Also get the joystick to work in the correct direction
	Done

Meet with cheever either this week or next to make new circuit
	Sent email
	1pm meeting today --> circuit now works!
	
Install ROS
	ROS Kinetic on ARM processor: wiki.ros.org/kinetic/Installation/Ubuntu
	(Only package not installed was ros-kinetic-roslz)
	Stepping through tutorials now

Space problem in the odroid? Running out of room after ROS install
	156 992 opencv
	99 816 opencv-contib
	5 756 DOcuments
	600 Downloads
	77 336 opencv.zip
	53 896 opencv_contrib.zip
	487 328 /home/odroid
	--> ways to save space:
		* delete the .zip files
		* sudo apt-get clean helps free some space of Ubuntu downloads
		* sudo apt-get remove <thing to remove>


---------------------------------------------

debugging with Matt:

helpful with hex and binary commands

the servotest and the maestro controller both work
the script was running alright, but commented-out driver section was the problem

---------------------------------------------------

git commands:
	Odroid push/pull:
		origin = 'myorigin', branch = 'master'
		git pull myorigin master
		git push myorigin
		...everything else is the same

	Hermes push/pull as usual 

-------------------------------------------------------
Post spring break week TODO:

Make a node that accepts commands (throttle and steering)
	Listens to command of steering angle and throttle from controller
	Essentially will redo the project_server client, and network_controller except with Nodes in ROS all on the Odroid

One node controlling car, another node listening to joystick and publishing the axis info

Change password for odroid

play with camera, line detection and line following
Joystick working with ROS
	Python node to listen to joystick throttle and steering commands and sends along to motors

Replace contoller with wireless controller
	Done

--------------------------------------------------------
Unix commands

df -h: memory check in MB
. ~/catkin_ws/devel/setup.bash: sources the bash to current terminal
lsmod: see all the drivers and modules in the system 
dmesg: see all things plugged into the computer
dmesg | grep -i tty: seaches the dmesg space for the "tty" string
apt-cache search - search for libs and packages

---------------------------------------------------------
Problems:

can listen to one another :)
issue when try to write to servo controller
	publishes steering on 20 second delay when line writing to the controller is active:
		self.controller.setAngle(0, steering)
	Writing to the actual controller
issue when writing to setPosition script:
	"int() argument must be a string or a number, not 'String'"
	"float" vs "Float64"
	Types converted between python and ROS std_msgs
got rid of issue when the pygame module prints debugging messages to the console
	Commented out the stuff in C, and compiled it from source

--------------------------------------------------------
send one message with both steering and throttle
	define own message type
	existing message type from ROS
	** Done
		FIxed via custom message, int32 and int32

blob finder software installed on Odroid
ROS cv camera reading the camera and publishing the image as a topic
	after that, line following like normal

Line folliwing working 

Prime Sense drivers on the Odroid
1.09 vs 1.08 specs
	1.09 is short range
	roslaunch openni2_launch openni2.launch

Killswitch also!


---------------------------------------------------------------
3/29

Have to manage the line follower. Currently, it actually follows
a line, using motors and steering to find it. But states after
no blobs are found is a problem. Need to mange:
- when no blobs are around --> trigger some kind of search event
- a search event is walking around until you see a large enough blob
- want to not call the search state accidentily, and then go back
into the following state
- search state can walk around slowly in a circle
- once blob that is large enough found go back into the following (start) state
- might need to seperate the start state with the following state
  --> start out in a start state, going slow with no steer
  --> if a blob event is found, then following state
  -->--> following state runs until the blobs are lost again

roslaunch openni2_launch openni2.launch

4/2
Something is up with the camera. I got the car working following lines on the
ground, but a few issues emerged when I was SSH'ing
- camera would fail out and stop working, stop reading blobs all of the sudden
- very slow when using the colorpicker for the blobfinder
- killswitch doesn't always work in the script. will kill the car, but script
will still run after
- Camera must be mounted higher to see all the blobs correctly.
- when camera dropped, had to find colors again
- search state still doesn't work that well
- camera calibration file also missing

All the camera errors don't really come up when mounted on my desk, running
with a display

*Get the shared library message at the launch of camera to go away
*Get a few things downloaded onto motion server (git, other packages)
*Meet with J and find out a mounting device for Otto

export ROS_MASTER_URI=http://192.168.1.104:11311

rosrun depthimage_to_laserscan depthimage_to_laserscan image:=/camera/depth/image_raw  --> runs the laserscan image

4/5
Mounted camera
	- for some reason depth cloud is really warped
Also the cv_bridge isnt working

